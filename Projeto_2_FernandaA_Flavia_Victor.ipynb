{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto_2_FernandaA_Flavia_Victor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernanda0402/Python/blob/master/Projeto_2_FernandaA_Flavia_Victor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWVfNAWILG7s"
      },
      "source": [
        "# **Projeto 2 de Introdução à Python**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxsAd1EELSf_"
      },
      "source": [
        "Alunos: Fernanda Araujo, Flávia Fialho e Victor Assis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbJEO_aLLaBG"
      },
      "source": [
        "#Questão 1\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from sklearn.datasets import load_iris\r\n",
        "from sklearn.linear_model import Perceptron\r\n",
        "iris = load_iris()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5Kw1Y-dOTfT"
      },
      "source": [
        "class Nosso_perceptron():\r\n",
        "\r\n",
        "    def __init__(self, no_of_inputs, threshold=100, learning_rate=0.01):\r\n",
        "        '''\r\n",
        "        método de inicialização que tem os seguintes atributos:\r\n",
        "        no_of_inputs: número de features passadas como input ao perceptron\r\n",
        "        threshold: número de iterações de atualização do peso\r\n",
        "        learning_rate: taxa com a qual os pesos são atualizados a cada iteração\r\n",
        "        weights: inicialização dos pesos (dica: pode inicializar com método np.zeros). Não se esquecer que o vetor dos pesos\r\n",
        "        terá no_of_inputs + 1 elementos por conta do bias que é o primeiro elemento.\r\n",
        "        '''\r\n",
        "        self.b = 0\r\n",
        "        self.weights = np.zeros(no_of_inputs)              \r\n",
        "        self.threshold = threshold\r\n",
        "        self.learning_rate = learning_rate\r\n",
        "           \r\n",
        "    def predict(self, inputs):\r\n",
        "      '''\r\n",
        "      método de implementação da função de ativação.\r\n",
        "      inputs: array com o conjunto de inputs (features). No projeto pedimos que considerassem o comprimento e largura da pétala da Iris.\r\n",
        "      Não se esquecer que o produto da função de ativação é um produto escalar e pode ser calculado pelo método np.dot\r\n",
        "      '''         \r\n",
        "      f = np.heaviside(np.dot(self.weights, inputs) + self.b, 0)\r\n",
        "      return f\r\n",
        "\r\n",
        "    def train(self, training_inputs, labels):\r\n",
        "      '''\r\n",
        "      método de treino. É aqui que os pesos são atualizados um certo número de vezes (determinado pelo valor do threshold).\r\n",
        "      Nesse método é feita a comparação entre o resultado da função de ativação (predição) e\r\n",
        "      o resultado esperado (label).\r\n",
        "      O método deve atualizar tanto os pesos quanto o bias (lembre que o bias é o primeiro valor do vetor peso e tem input 1.)\r\n",
        "      A atualização é feita iterativamente um número (threshold) de vezes.\r\n",
        "      '''\r\n",
        "      for i in range(self.threshold):\r\n",
        "          for j in range(len(training_inputs)):\r\n",
        "            prediction = self.predict(training_inputs[j])\r\n",
        "            erro = labels[j] - prediction\r\n",
        "            self.weights += self.learning_rate * erro * training_inputs[j]\r\n",
        "            self.b += self.learning_rate * erro * 1      # seu input é 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdZAwZNmOV6q",
        "outputId": "6d58d728-158a-4704-8d4f-51a1814a5619"
      },
      "source": [
        "print(iris.target_names)    # target = label\r\n",
        "print(iris.feature_names)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyIGPU0NOXrq",
        "outputId": "1eb76320-6d56-4e07-ee9d-ffbdb5036e5c"
      },
      "source": [
        "#Questão 2\r\n",
        "\r\n",
        "perceptron = Nosso_perceptron(2)\r\n",
        "X = iris.data[:, (2,3)]             # inputs\r\n",
        "y = (iris.target == 0).astype(int)  # label = iris setosa. Retorna uma lista com os labels da Iris-Setosa. 0: não, 1: sim\r\n",
        "print(y)\r\n",
        "\r\n",
        "treino = perceptron.train(X,y)\r\n",
        "pred = perceptron.predict([1, 0.5])\r\n",
        "print(pred)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeujsKf2Oauk",
        "outputId": "c9f831d9-7218-4f43-b383-4cbd6342441c"
      },
      "source": [
        "#Questão 3\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from sklearn.datasets import load_iris\r\n",
        "from sklearn.linear_model import Perceptron\r\n",
        "\r\n",
        "iris = load_iris() \r\n",
        "print(iris.target_names)    # target = label\r\n",
        "print(iris.feature_names)\r\n",
        "\r\n",
        "#Pelo primeiro print acima, as features são: 0: sepal length, 1: sepal width, 2: petal length, 3: petal width\r\n",
        "#Vamos selecionar somente as features comprimento a largura da pétala:\r\n",
        "X = iris.data[:, (2,3)]             #nos retorna um array com 150 conjuntos de inputs\r\n",
        "y = (iris.target == 0).astype(int)  # label = iris setosa. Retorna uma lista com os labels da Iris-Setosa. 0: não, 1: sim\r\n",
        "\r\n",
        "perceptron_clf = Perceptron()      # dois inputs: comprimento e largura da pétala\r\n",
        "perceptron_clf.fit(X,y)            # Train\r\n",
        "\r\n",
        "y_pred = perceptron_clf.predict([[1,0.5]])  #predict\r\n",
        "\r\n",
        "print(y_pred)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTnpwOcuOdHu",
        "outputId": "70ebb78c-dd51-4fb6-aba9-d843e6c00ee5"
      },
      "source": [
        "# Teste 1\r\n",
        "\r\n",
        "y_pred = perceptron_clf.predict([[1,0.5]])  #predict\r\n",
        "nosso = perceptron.predict([1,0.5])\r\n",
        "print(y_pred)\r\n",
        "print(nosso)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Umn5jQjuOd4m",
        "outputId": "2399dc5a-3499-459b-ed8f-51827f16001c"
      },
      "source": [
        "# Teste 2\r\n",
        "\r\n",
        "y_pred = perceptron_clf.predict([[4,0.5]])  #predict\r\n",
        "nosso = perceptron.predict([4,0.5])\r\n",
        "print(y_pred)\r\n",
        "print(nosso)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K52MVtTbOiZX",
        "outputId": "0341b279-a977-4ef0-ebc0-f68b33b1c2bb"
      },
      "source": [
        "# Teste 3\r\n",
        "\r\n",
        "y_pred = perceptron_clf.predict([[3.3,0.5]])  #predict\r\n",
        "nosso = perceptron.predict([3.3,0.5])\r\n",
        "print(y_pred)\r\n",
        "print(nosso)\r\n",
        "print(X)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "0.0\n",
            "[[1.4 0.2]\n",
            " [1.4 0.2]\n",
            " [1.3 0.2]\n",
            " [1.5 0.2]\n",
            " [1.4 0.2]\n",
            " [1.7 0.4]\n",
            " [1.4 0.3]\n",
            " [1.5 0.2]\n",
            " [1.4 0.2]\n",
            " [1.5 0.1]\n",
            " [1.5 0.2]\n",
            " [1.6 0.2]\n",
            " [1.4 0.1]\n",
            " [1.1 0.1]\n",
            " [1.2 0.2]\n",
            " [1.5 0.4]\n",
            " [1.3 0.4]\n",
            " [1.4 0.3]\n",
            " [1.7 0.3]\n",
            " [1.5 0.3]\n",
            " [1.7 0.2]\n",
            " [1.5 0.4]\n",
            " [1.  0.2]\n",
            " [1.7 0.5]\n",
            " [1.9 0.2]\n",
            " [1.6 0.2]\n",
            " [1.6 0.4]\n",
            " [1.5 0.2]\n",
            " [1.4 0.2]\n",
            " [1.6 0.2]\n",
            " [1.6 0.2]\n",
            " [1.5 0.4]\n",
            " [1.5 0.1]\n",
            " [1.4 0.2]\n",
            " [1.5 0.2]\n",
            " [1.2 0.2]\n",
            " [1.3 0.2]\n",
            " [1.4 0.1]\n",
            " [1.3 0.2]\n",
            " [1.5 0.2]\n",
            " [1.3 0.3]\n",
            " [1.3 0.3]\n",
            " [1.3 0.2]\n",
            " [1.6 0.6]\n",
            " [1.9 0.4]\n",
            " [1.4 0.3]\n",
            " [1.6 0.2]\n",
            " [1.4 0.2]\n",
            " [1.5 0.2]\n",
            " [1.4 0.2]\n",
            " [4.7 1.4]\n",
            " [4.5 1.5]\n",
            " [4.9 1.5]\n",
            " [4.  1.3]\n",
            " [4.6 1.5]\n",
            " [4.5 1.3]\n",
            " [4.7 1.6]\n",
            " [3.3 1. ]\n",
            " [4.6 1.3]\n",
            " [3.9 1.4]\n",
            " [3.5 1. ]\n",
            " [4.2 1.5]\n",
            " [4.  1. ]\n",
            " [4.7 1.4]\n",
            " [3.6 1.3]\n",
            " [4.4 1.4]\n",
            " [4.5 1.5]\n",
            " [4.1 1. ]\n",
            " [4.5 1.5]\n",
            " [3.9 1.1]\n",
            " [4.8 1.8]\n",
            " [4.  1.3]\n",
            " [4.9 1.5]\n",
            " [4.7 1.2]\n",
            " [4.3 1.3]\n",
            " [4.4 1.4]\n",
            " [4.8 1.4]\n",
            " [5.  1.7]\n",
            " [4.5 1.5]\n",
            " [3.5 1. ]\n",
            " [3.8 1.1]\n",
            " [3.7 1. ]\n",
            " [3.9 1.2]\n",
            " [5.1 1.6]\n",
            " [4.5 1.5]\n",
            " [4.5 1.6]\n",
            " [4.7 1.5]\n",
            " [4.4 1.3]\n",
            " [4.1 1.3]\n",
            " [4.  1.3]\n",
            " [4.4 1.2]\n",
            " [4.6 1.4]\n",
            " [4.  1.2]\n",
            " [3.3 1. ]\n",
            " [4.2 1.3]\n",
            " [4.2 1.2]\n",
            " [4.2 1.3]\n",
            " [4.3 1.3]\n",
            " [3.  1.1]\n",
            " [4.1 1.3]\n",
            " [6.  2.5]\n",
            " [5.1 1.9]\n",
            " [5.9 2.1]\n",
            " [5.6 1.8]\n",
            " [5.8 2.2]\n",
            " [6.6 2.1]\n",
            " [4.5 1.7]\n",
            " [6.3 1.8]\n",
            " [5.8 1.8]\n",
            " [6.1 2.5]\n",
            " [5.1 2. ]\n",
            " [5.3 1.9]\n",
            " [5.5 2.1]\n",
            " [5.  2. ]\n",
            " [5.1 2.4]\n",
            " [5.3 2.3]\n",
            " [5.5 1.8]\n",
            " [6.7 2.2]\n",
            " [6.9 2.3]\n",
            " [5.  1.5]\n",
            " [5.7 2.3]\n",
            " [4.9 2. ]\n",
            " [6.7 2. ]\n",
            " [4.9 1.8]\n",
            " [5.7 2.1]\n",
            " [6.  1.8]\n",
            " [4.8 1.8]\n",
            " [4.9 1.8]\n",
            " [5.6 2.1]\n",
            " [5.8 1.6]\n",
            " [6.1 1.9]\n",
            " [6.4 2. ]\n",
            " [5.6 2.2]\n",
            " [5.1 1.5]\n",
            " [5.6 1.4]\n",
            " [6.1 2.3]\n",
            " [5.6 2.4]\n",
            " [5.5 1.8]\n",
            " [4.8 1.8]\n",
            " [5.4 2.1]\n",
            " [5.6 2.4]\n",
            " [5.1 2.3]\n",
            " [5.1 1.9]\n",
            " [5.9 2.3]\n",
            " [5.7 2.5]\n",
            " [5.2 2.3]\n",
            " [5.  1.9]\n",
            " [5.2 2. ]\n",
            " [5.4 2.3]\n",
            " [5.1 1.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSUlF67eOkyA",
        "outputId": "1b297b10-cea3-498c-94c3-29990aa77ea1"
      },
      "source": [
        "# Teste 4\r\n",
        "\r\n",
        "y_pred = perceptron_clf.predict([[3.2,0.5]])  #predict\r\n",
        "nosso = perceptron.predict([3.2,0.5])\r\n",
        "print(y_pred)\r\n",
        "print(nosso)\r\n",
        "#print(X)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gowEBLjIOnCh",
        "outputId": "2829f579-169e-4453-c70f-df55714de1a0"
      },
      "source": [
        "# Teste 5\r\n",
        "\r\n",
        "y_pred = perceptron_clf.predict([[3.1,0.5]])  #predict\r\n",
        "nosso = perceptron.predict([3.1,0.5])\r\n",
        "print(y_pred)\r\n",
        "print(nosso)\r\n",
        "#print(X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7skurEwOpma"
      },
      "source": [
        "Questão 4: Você pode pensar em algum outro exemplo em que possa aplica o modelo do Perceptron? Quando esse modelo falha?\r\n",
        "\r\n",
        "Podemos aplicar o modelo do Perceptron para todo sistema binário, que nos devolva as respostas \"sim\" ou \"não\". \r\n",
        "\r\n",
        "Esse método falha quando queremos obter um dado que não está presente no conjunto dos inputs, como podemos ver no Teste 5, em que aplicamos o valor de 3.1 para o comprimento da pétala e obtivemos um erro, já que este valor não está presente no conjunto dos inputs."
      ]
    }
  ]
}