{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto_2_FernandaA_Flavia_Victor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernanda0402/Python/blob/master/Projeto_2_FernandaA_Flavia_Victor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWVfNAWILG7s"
      },
      "source": [
        "# **Projeto 2 de Introdução à Python**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxsAd1EELSf_"
      },
      "source": [
        "Alunos: Fernanda Araujo, Flávia Fialho e Victor Assis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbJEO_aLLaBG"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dnFK8kYOl3Z"
      },
      "source": [
        "Função de ativação: $\n",
        "    ativação=\\left\\{\n",
        "                \\begin{array}{ll}\n",
        "                  1, se \\sum_j w_j x_j + b > 0\\\\\n",
        "                  0, se \\sum_j w_j x_j + b \\leq 0\\\\\n",
        "                \\end{array}\n",
        "              \\right.\n",
        "  $\n",
        "\n",
        "Podemos incorporar b no somatório da primeira linha da equação acima, considerando: $w_0=b$ e $x_0 = 1$. Sendo assim, a função de ativação pode ser reescrita como:\n",
        "\n",
        "$\n",
        "    f(x)=\\left\\{\n",
        "                \\begin{array}{ll}\n",
        "                  1, se \\sum_{j=0}^{N} w_j x_j > 0\\\\\n",
        "                  0, para \\; o \\; resto\\\\\n",
        "                \\end{array}\n",
        "              \\right.\n",
        "  $\n",
        "\n",
        "O $b$ foi incorporado. Ele também é conhecido como **bias**, como  peso $w_0 = b$ do input $x_0=1$ percepton.\n",
        "\n",
        "Esta função é a *Heaviside Stepfunction*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhA0wgQJMxsQ"
      },
      "source": [
        "#Criando a classe\n",
        "## ESQUELETO DE CLASSE PERCEPTRON\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "class Perceptron():\n",
        "\n",
        "    def __init__(self, no_of_inputs, threshold=100, learning_rate=0.01):\n",
        "        '''\n",
        "        método de inicialização que tem os seguintes atributos:\n",
        "        no_of_inputs: número de features passadas como input ao perceptron\n",
        "        threshold: número de iterações de atualização do peso\n",
        "        learning_rate: taxa com a qual os pesos são atualizados a cada iteração\n",
        "        weights: inicialização dos pesos (dica: pode inicializar com método np.zeros). Não se esquecer que o vetor dos pesos\n",
        "        terá no_of_inputs + 1 elementos por conta do bias que é o primeiro elemento.\n",
        "        '''\n",
        "        #self.weights = np.array(b,wj)\n",
        "        #self.inputs = np.array(1,xj) \n",
        "        \n",
        "           \n",
        "    def predict(self, inputs):\n",
        "      '''\n",
        "      método de implementação da função de ativação.\n",
        "      inputs: array com o conjunto de inputs (features). No projeto pedimos que considerassem o comprimento e largura da pétala da Iris.\n",
        "      Não se esquecer que o produto da função de ativação é um produto escalar e pode ser calculado pelo método np.dot\n",
        "      '''   \n",
        "      activation = weights\n",
        "      for i in range(len(inputs)-1):\n",
        "        activation += weights[i + 1] * inputs[i]\n",
        "      return 1.0 if activation >= 0.0 else 0.0\n",
        "      \n",
        "\n",
        "    def train(self, training_inputs, labels):\n",
        "      '''\n",
        "      método de treino. É aqui que os pesos são atualizados um certo número de vezes (determinado pelo valor do threshold).\n",
        "      Nesse método é feita a comparação entre o resultado da função de ativação (predição) e\n",
        "      o resultado esperado (label).\n",
        "      O método deve atualizar tanto os pesos quanto o bias (lembre que o bias é o primeiro valor do vetor peso e tem input 1.)\n",
        "      A atualização é feita iterativamente um número (threshold) de vezes.\n",
        "      '''\n",
        "      weights = [0.0 for i in range(len(training_inputs[0]))]\n",
        "      for epoca in range(threshold):\n",
        "        sum_error = 0.0\n",
        "        for inputs in training_inputs:\n",
        "          prediction = predict(inputs, weights)\n",
        "          error = inputs[-1] - prediction\n",
        "          sum_error += error**2\n",
        "          weights[0] = weights[0] + learning_rate * error\n",
        "          for i in range(len(inputs)-1):\n",
        "            weights[i + 1] = weights[i + 1] + learning_rate * error * inputs[i]\n",
        "\t\t    #print('>epoca=%d, lrate=%.3f, error=%.3f' % (epoca, learning_rate, sum_error))\n",
        "      return weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra5kG2OUEEbk",
        "outputId": "21121b87-e0d5-4ed9-f15c-5bad3270a60e"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "iris = load_iris() # returns a dictionary-like object\n",
        "# características (features) das flores Iris:\n",
        "print(iris.target_names)    # target = label\n",
        "print(iris.feature_names)\n",
        "\n",
        "# Pelo primeiro print acima, as features são: 0: sepal length, 1: sepal width, 2: petal length, 3: petal width\n",
        "# Vamos selecionar somente as features petal length e petal width:\n",
        "X = iris.data[:, (2,3)]  # nos retorna um array com 150 conjuntos de inputs\n",
        "#len(iris.data[:,(2,3)])\n",
        "y = (iris.target == 0).astype(int)  # label = iris setosa. Retorna uma lista com os labels da Iris-Setosa. 0: não, 1: sim\n",
        "\n",
        "perceptron_clf = Perceptron()      # dois inputs: comprimento e largura da pétala\n",
        "perceptron_clf.fit(X,y)            # Train\n",
        "\n",
        "y_pred = perceptron_clf.predict([[1,0.5]])  # predict\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkXPQQv8EUsO",
        "outputId": "61a84104-0daf-46fa-ed45-09c47b761a1e"
      },
      "source": [
        "def predict(row, weights):\n",
        "\tactivation = weights[0]\n",
        "\tfor i in range(len(row)-1):\n",
        "\t\tactivation += weights[i + 1] * row[i]\n",
        "\treturn 1.0 if activation >= 0.0 else 0.0\n",
        "\n",
        "\n",
        "dataset = iris.data[:, (2,3)]\n",
        "weights = [-0.1, 0.20653640140000007, -0.23418117710000003]\n",
        "for row in dataset:\n",
        "\tprediction = predict(row, weights)\n",
        "\tprint(\"Expected=%d, Predicted=%d\" % (row[-1], prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=2, Predicted=1\n",
            "Expected=1, Predicted=1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eRyr5epElfh",
        "outputId": "0ef4de3f-fc30-4c5e-f8f5-ddb4ec8fb65b"
      },
      "source": [
        "def train_weights(train, l_rate, n_epoch):\n",
        "\tweights = [0.0 for i in range(len(train[0]))]\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tsum_error = 0.0\n",
        "\t\tfor row in train:\n",
        "\t\t\tprediction = predict(row, weights)\n",
        "\t\t\terror = row[-1] - prediction\n",
        "\t\t\tsum_error += error**2\n",
        "\t\t\tweights[0] = weights[0] + l_rate * error\n",
        "\t\t\tfor i in range(len(row)-1):\n",
        "\t\t\t\tweights[i + 1] = weights[i + 1] + l_rate * error * row[i]\n",
        "\t\t#print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
        "\treturn weights\n",
        " \n",
        "# Calculate weights\n",
        "dataset = iris.data[:, (2,3)]\n",
        "l_rate = 0.01\n",
        "n_epoch = 100\n",
        "weights = train_weights(dataset, l_rate, n_epoch)\n",
        "print(weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[30.28000000000156, 305.99399999999946]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "74g-VXh4E_Z9",
        "outputId": "4c07e264-f68f-424d-edc2-f7ab15806053"
      },
      "source": [
        "def predict(self, inputs):\n",
        "      '''\n",
        "      método de implementação da função de ativação.\n",
        "      inputs: array com o conjunto de inputs (features). No projeto pedimos que considerassem o comprimento e largura da pétala da Iris.\n",
        "      Não se esquecer que o produto da função de ativação é um produto escalar e pode ser calculado pelo método np.dot\n",
        "      '''   \n",
        "      #iris.data[:, (2,3)]\n",
        "      wj = 1\n",
        "      b=1\n",
        "      weights = np.array(1)\n",
        "      inputs = np.array(X)  \n",
        "      activation = []# weights\n",
        "      #se activation = weights aparece o erro 'numpy.ndarray' object has no attribute 'extend'\n",
        "      for i in range(len(inputs)-1):\n",
        "        activation.extend(activation + np.dot(weights[i+1], inputs[i]))\n",
        "      return 1.0 if activation >= 0.0 else 0.0\n",
        "\n",
        "print(predict(1, iris.data[:, (2,3)]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-640c90266aca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-640c90266aca>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0;31m#se activation = weights aparece o erro 'numpy.ndarray' object has no attribute 'extend'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mactivation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
          ]
        }
      ]
    }
  ]
}